{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q --upgrade pip\n",
    "!pip3 install -q pandas numpy matplotlib seaborn openpyxl climateserv requests netCDF4 xarray pyproj statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Calculate the path to the scripts folder relative to the current notebook.\n",
    "scripts_dir = Path(\"../../\").resolve()\n",
    "\n",
    "# Add the scripts directory to the sys.path if it's not already there.\n",
    "if str(scripts_dir) not in sys.path:\n",
    "    sys.path.append(str(scripts_dir))\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos y preparación inicial (igual que tu código)\n",
    "df = pd.read_csv(\"../../data/processed_data/wells_data_gambia_for_machine_learning.csv\")\n",
    "unique_values = df['DepthToGroundwater'].unique()\n",
    "value_to_int = {value: idx for idx, value in enumerate(unique_values)}\n",
    "df['DepthToGroundwater'] = df['DepthToGroundwater'].map(value_to_int)\n",
    "\n",
    "# Preparación de los conjuntos de datos (igual que tu código)\n",
    "unique_ids = df['ID'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=0.1, random_state=42)\n",
    "train_df = df[df['ID'].isin(train_ids)]\n",
    "test_df = df[df['ID'].isin(test_ids)]\n",
    "\n",
    "X_train = train_df.drop(columns=['GROUNDWATER_LEVEL', 'ID', 'Date'])\n",
    "y_train = train_df['GROUNDWATER_LEVEL']\n",
    "X_test = test_df.drop(columns=['GROUNDWATER_LEVEL', 'ID', 'Date'])\n",
    "y_test = test_df['GROUNDWATER_LEVEL']\n",
    "\n",
    "# Prepara los grupos para GroupKFold (igual que tu código)\n",
    "groups = df['ID']\n",
    "\n",
    "def create_gbm_param_grid():\n",
    "    \"\"\"\n",
    "    Crea una cuadrícula de parámetros para el GradientBoostingRegressor.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'subsample': [0.8, 1.0]  # Fracción de muestras para ajustar los aprendices individuales\n",
    "    }\n",
    "    return param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "Best parameters for GBM: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Mean MSE from group cross-validation: 46.1089520520666\n",
      "Mean MAE from group cross-validation: 4.998856982979899\n",
      "Mean R² from group cross-validation: -0.4049811386436691\n"
     ]
    }
   ],
   "source": [
    "# Configuración de GridSearchCV con GroupKFold para GBM\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "param_grid_gbm = create_gbm_param_grid()\n",
    "\n",
    "gbm = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "grid_search_gbm = GridSearchCV(\n",
    "    estimator=gbm,\n",
    "    param_grid=param_grid_gbm,\n",
    "    cv=gkf,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    error_score=np.nan\n",
    ")\n",
    "\n",
    "# Asegúrate de que 'groups' solo contenga los IDs correspondientes a 'X_train'\n",
    "groups_train = train_df['ID']\n",
    "\n",
    "# Ahora puedes hacer el ajuste con GridSearchCV\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    grid_search_gbm.fit(X=X_train, y=y_train, groups=groups_train)\n",
    "\n",
    "\n",
    "# Mejores parámetros y modelo\n",
    "best_params_gbm = grid_search_gbm.best_params_\n",
    "print(\"Best parameters for GBM:\", best_params_gbm)\n",
    "\n",
    "# Configuración del mejor modelo GBM\n",
    "best_gbm = GradientBoostingRegressor(\n",
    "    n_estimators=best_params_gbm['n_estimators'],\n",
    "    learning_rate=best_params_gbm['learning_rate'],\n",
    "    max_depth=best_params_gbm['max_depth'],\n",
    "    min_samples_split=best_params_gbm['min_samples_split'],\n",
    "    min_samples_leaf=best_params_gbm['min_samples_leaf'],\n",
    "    subsample=best_params_gbm['subsample'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Validación cruzada para GBM\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# Asegúrate de que 'groups_train' solo contenga los IDs correspondientes a 'X_train'\n",
    "groups_train = train_df['ID']\n",
    "\n",
    "# Utiliza 'groups_train' en lugar de 'groups' en cross_val_score\n",
    "mse_scores = cross_val_score(best_gbm, X_train, y_train, groups=groups_train, cv=gkf, scoring=mse_scorer)\n",
    "mae_scores = cross_val_score(best_gbm, X_train, y_train, groups=groups_train, cv=gkf, scoring=mae_scorer)\n",
    "r2_scores = cross_val_score(best_gbm, X_train, y_train, groups=groups_train, cv=gkf, scoring=r2_scorer)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"Mean MSE from group cross-validation: {-mse_scores.mean()}\")\n",
    "print(f\"Mean MAE from group cross-validation: {-mae_scores.mean()}\")\n",
    "print(f\"Mean R² from group cross-validation: {r2_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GradientBoostingRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m learning_curve\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Asumiendo que 'best_gbm' es tu modelo ajustado\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Importancia de características\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m feature_importance \u001b[39m=\u001b[39m best_gbm\u001b[39m.\u001b[39;49mfeature_importances_\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m sorted_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(feature_importance)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/franciscofurey/00DataScience/aquaViva/notebooks/machine_learning/gradient_boosting_machines.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pos \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(sorted_idx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m.5\u001b[39m\n",
      "File \u001b[0;32m~/00DataScience/OpenAi/venv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:735\u001b[0m, in \u001b[0;36mBaseGradientBoosting.feature_importances_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    716\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_importances_\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    717\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The impurity-based feature importances.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[39m    The higher, the more important the feature.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[39m        array of zeros.\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_initialized()\n\u001b[1;32m    737\u001b[0m     relevant_trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    738\u001b[0m         tree\n\u001b[1;32m    739\u001b[0m         \u001b[39mfor\u001b[39;00m stage \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\n\u001b[1;32m    740\u001b[0m         \u001b[39mfor\u001b[39;00m tree \u001b[39min\u001b[39;00m stage\n\u001b[1;32m    741\u001b[0m         \u001b[39mif\u001b[39;00m tree\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mnode_count \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    742\u001b[0m     ]\n\u001b[1;32m    743\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m relevant_trees:\n\u001b[1;32m    744\u001b[0m         \u001b[39m# degenerate case where all trees have only one node\u001b[39;00m\n",
      "File \u001b[0;32m~/00DataScience/OpenAi/venv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:367\u001b[0m, in \u001b[0;36mBaseGradientBoosting._check_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_initialized\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    366\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that the estimator is initialized, raising an error if not.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/00DataScience/OpenAi/venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1462\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not an estimator instance.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (estimator))\n\u001b[1;32m   1461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1462\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GradientBoostingRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Asumiendo que 'best_gbm' es tu modelo ajustado\n",
    "\n",
    "# Importancia de características\n",
    "feature_importance = best_gbm.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, np.array(X_train.columns)[sorted_idx])\n",
    "plt.title('Importancia de Características')\n",
    "\n",
    "# Curvas de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_gbm, X_train, y_train, cv=gkf, n_jobs=-1, \n",
    "    train_sizes=np.linspace(.1, 1.0, 5)\n",
    ")\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Curvas de Aprendizaje\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
