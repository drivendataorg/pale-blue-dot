{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q --upgrade pip\n",
    "!pip3 install -q pandas numpy matplotlib seaborn openpyxl climateserv requests netCDF4 xarray pyproj statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Calculate the path to the scripts folder relative to the current notebook.\n",
    "scripts_dir = Path(\"../../\").resolve()\n",
    "\n",
    "# Add the scripts directory to the sys.path if it's not already there.\n",
    "if str(scripts_dir) not in sys.path:\n",
    "    sys.path.append(str(scripts_dir))\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Didnt work to much time (1120 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos y preparación inicial\n",
    "df = pd.read_csv(\"../../data/processed_data/wells_data_gambia_for_machine_learning.csv\")\n",
    "unique_values = df['DepthToGroundwater'].unique()\n",
    "value_to_int = {value: idx for idx, value in enumerate(unique_values)}\n",
    "df['DepthToGroundwater'] = df['DepthToGroundwater'].map(value_to_int)\n",
    "\n",
    "# Preparación de los conjuntos de datos\n",
    "unique_ids = df['ID'].unique()\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=0.1, random_state=42)\n",
    "train_df = df[df['ID'].isin(train_ids)]\n",
    "test_df = df[df['ID'].isin(test_ids)]\n",
    "\n",
    "X_train = train_df.drop(columns=['GROUNDWATER_LEVEL', 'ID', 'Date'])\n",
    "y_train = train_df['GROUNDWATER_LEVEL']\n",
    "X_test = test_df.drop(columns=['GROUNDWATER_LEVEL', 'ID', 'Date'])\n",
    "y_test = test_df['GROUNDWATER_LEVEL']\n",
    "\n",
    "# Preparación para GroupKFold\n",
    "groups_train = train_df['ID']\n",
    "\n",
    "# Definición de la cuadrícula de parámetros para SVR\n",
    "param_grid_svr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'epsilon': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV con GroupKFold para SVR\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "svr = SVR()\n",
    "\n",
    "grid_search_svr = GridSearchCV(\n",
    "    estimator=svr,\n",
    "    param_grid=param_grid_svr,\n",
    "    cv=gkf,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Ajuste del modelo SVR\n",
    "grid_search_svr.fit(X=X_train, y=y_train, groups=groups_train)\n",
    "\n",
    "# Mejores parámetros y modelo\n",
    "best_params_svr = grid_search_svr.best_params_\n",
    "print(\"Best parameters for SVR:\", best_params_svr)\n",
    "\n",
    "# Configuración del mejor modelo SVR\n",
    "best_svr = SVR(\n",
    "    C=best_params_svr['C'],\n",
    "    epsilon=best_params_svr['epsilon'],\n",
    "    kernel=best_params_svr['kernel'],\n",
    "    gamma=best_params_svr['gamma']\n",
    ")\n",
    "\n",
    "# Métricas de rendimiento para SVR\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "mse_scores = cross_val_score(best_svr, X_train, y_train, groups=groups_train, cv=gkf, scoring=mse_scorer)\n",
    "mae_scores = cross_val_score(best_svr, X_train, y_train, groups=groups_train, cv=gkf, scoring=mae_scorer)\n",
    "r2_scores = cross_val_score(best_svr, X_train, y_train, groups=groups_train, cv=gkf, scoring=r2_scorer)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"Mean MSE from group cross-validation: {-mse_scores.mean()}\")\n",
    "print(f\"Mean MAE from group cross-validation: {-mae_scores.mean()}\")\n",
    "print(f\"Mean R² from group cross-validation: {r2_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura la validación cruzada\n",
    "cv_results = cross_validate(\n",
    "    best_svr, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=gkf, \n",
    "    scoring={'mse': mse_scorer, 'mae': mae_scorer, 'r2': r2_scorer},\n",
    "    return_train_score=True,\n",
    "    groups=groups_train\n",
    ")\n",
    "\n",
    "# Imprime los resultados de la validación cruzada\n",
    "print(\"Validación Cruzada - SVR\")\n",
    "print(\"MSE (Train):\", -cv_results['train_mse'].mean()) \n",
    "print(\"MSE (Test):\", -cv_results['test_mse'].mean())\n",
    "print(\"MAE (Train):\", -cv_results['train_mae'].mean())\n",
    "print(\"MAE (Test):\", -cv_results['test_mae'].mean())\n",
    "print(\"R² (Train):\", cv_results['train_r2'].mean())\n",
    "print(\"R² (Test):\", cv_results['test_r2'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
